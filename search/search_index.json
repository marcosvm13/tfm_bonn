{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BONN: Bio-inspired Olfactory Neural Networks Este proyecto implementa y analiza una familia de modelos de redes neuronales artificiales inspirados en el sistema olfativo de los insectos. Los modelos, como BONN y GateBONN, est\u00e1n dise\u00f1ados para ser eficientes en entornos de aprendizaje r\u00e1pido y con recursos limitados, emulando principios como codificaci\u00f3n dispersa, especializaci\u00f3n funcional y robustez estructural. Contenido principal Definici\u00f3n de modelos bioinspirados (BONN, GateBONN, ELM, RFM) Experimentaci\u00f3n sobre capacidad de generalizaci\u00f3n, escasez, robustez y aprendizaje r\u00e1pido Comparativas frente a MLPs tradicionales Evaluaci\u00f3n de t\u00e9cnicas como pruning, ensambles y codificaci\u00f3n aleatoria Estructura del repositorio src/ \u251c\u2500\u2500 bonn/ # Definici\u00f3n de arquitectura BONN \u251c\u2500\u2500 gatebonn/ # Modelo GateBONN en PyTorch \u251c\u2500\u2500 analysis/ # M\u00e9tricas, gr\u00e1ficos y an\u00e1lisis \u251c\u2500\u2500 training/ # Funciones de entrenamiento y validaci\u00f3n \u251c\u2500\u2500 experiments/ # Scripts de evaluaci\u00f3n y benchmarking \u2514\u2500\u2500 app.py # Script principal de ejecuci\u00f3n centralizada Documentaci\u00f3n Installation : C\u00f3mo instalar y configurar el entorno Usage : Ejecuci\u00f3n de los experimentos Technical Details : Dise\u00f1o interno de los modelos y su justificaci\u00f3n biol\u00f3gica","title":"Inicio"},{"location":"#bonn-bio-inspired-olfactory-neural-networks","text":"Este proyecto implementa y analiza una familia de modelos de redes neuronales artificiales inspirados en el sistema olfativo de los insectos. Los modelos, como BONN y GateBONN, est\u00e1n dise\u00f1ados para ser eficientes en entornos de aprendizaje r\u00e1pido y con recursos limitados, emulando principios como codificaci\u00f3n dispersa, especializaci\u00f3n funcional y robustez estructural.","title":"BONN: Bio-inspired Olfactory Neural Networks"},{"location":"#contenido-principal","text":"Definici\u00f3n de modelos bioinspirados (BONN, GateBONN, ELM, RFM) Experimentaci\u00f3n sobre capacidad de generalizaci\u00f3n, escasez, robustez y aprendizaje r\u00e1pido Comparativas frente a MLPs tradicionales Evaluaci\u00f3n de t\u00e9cnicas como pruning, ensambles y codificaci\u00f3n aleatoria","title":"Contenido principal"},{"location":"#estructura-del-repositorio","text":"src/ \u251c\u2500\u2500 bonn/ # Definici\u00f3n de arquitectura BONN \u251c\u2500\u2500 gatebonn/ # Modelo GateBONN en PyTorch \u251c\u2500\u2500 analysis/ # M\u00e9tricas, gr\u00e1ficos y an\u00e1lisis \u251c\u2500\u2500 training/ # Funciones de entrenamiento y validaci\u00f3n \u251c\u2500\u2500 experiments/ # Scripts de evaluaci\u00f3n y benchmarking \u2514\u2500\u2500 app.py # Script principal de ejecuci\u00f3n centralizada","title":"Estructura del repositorio"},{"location":"#documentacion","text":"Installation : C\u00f3mo instalar y configurar el entorno Usage : Ejecuci\u00f3n de los experimentos Technical Details : Dise\u00f1o interno de los modelos y su justificaci\u00f3n biol\u00f3gica","title":"Documentaci\u00f3n"},{"location":"installation/","text":"Installation Stable release To install tfm_bonn, run this command in your terminal: pip install tfm_bonn This is the preferred method to install tfm_bonn, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From sources The sources for tfm_bonn can be downloaded from the Github repo . You can either clone the public repository: git clone git://github.com/marcosvm13/tfm_bonn Or download the tarball : curl -OJL https://github.com/marcosvm13/tfm_bonn/tarball/master Once you have a copy of the source, you can install it with: python setup.py install Instalaci\u00f3n del proyecto BONN Este proyecto puede ejecutarse en entornos con GPU o CPU, aunque se recomienda el uso de GPU con soporte CUDA para experimentar con CuPy y PyTorch eficientemente. Requisitos Python 3.9 o superior CUDA (si se usa GPU + CuPy) Instalaci\u00f3n con entorno virtual python -m venv venv source venv/bin/activate # En Windows: venv\\Scripts\\activate pip install --upgrade pip pip install -r requirements.txt CuPy seg\u00fan tu versi\u00f3n de CUDA Instala cupy correspondiente a tu versi\u00f3n CUDA (verifica con nvcc --version ): pip install cupy-cuda12x # Para CUDA 12.x # o pip install cupy-cuda11x # Para CUDA 11.x Si no dispones de GPU, puedes eliminar cupy del proyecto y reemplazarlo por numpy en el c\u00f3digo. Descarga de datasets Los experimentos utilizan MNIST. PyTorch lo descarga autom\u00e1ticamente en la primera ejecuci\u00f3n. ./data/ # Se crea al correr los scripts por primera vez Prueba r\u00e1pida python src/app.py Esto ejecuta un pipeline de ejemplo con la arquitectura BONN.","title":"Instalaci\u00f3n"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install tfm_bonn, run this command in your terminal: pip install tfm_bonn This is the preferred method to install tfm_bonn, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-sources","text":"The sources for tfm_bonn can be downloaded from the Github repo . You can either clone the public repository: git clone git://github.com/marcosvm13/tfm_bonn Or download the tarball : curl -OJL https://github.com/marcosvm13/tfm_bonn/tarball/master Once you have a copy of the source, you can install it with: python setup.py install","title":"From sources"},{"location":"installation/#instalacion-del-proyecto-bonn","text":"Este proyecto puede ejecutarse en entornos con GPU o CPU, aunque se recomienda el uso de GPU con soporte CUDA para experimentar con CuPy y PyTorch eficientemente.","title":"Instalaci\u00f3n del proyecto BONN"},{"location":"installation/#requisitos","text":"Python 3.9 o superior CUDA (si se usa GPU + CuPy)","title":"Requisitos"},{"location":"installation/#instalacion-con-entorno-virtual","text":"python -m venv venv source venv/bin/activate # En Windows: venv\\Scripts\\activate pip install --upgrade pip pip install -r requirements.txt","title":"Instalaci\u00f3n con entorno virtual"},{"location":"installation/#cupy-segun-tu-version-de-cuda","text":"Instala cupy correspondiente a tu versi\u00f3n CUDA (verifica con nvcc --version ): pip install cupy-cuda12x # Para CUDA 12.x # o pip install cupy-cuda11x # Para CUDA 11.x Si no dispones de GPU, puedes eliminar cupy del proyecto y reemplazarlo por numpy en el c\u00f3digo.","title":"CuPy seg\u00fan tu versi\u00f3n de CUDA"},{"location":"installation/#descarga-de-datasets","text":"Los experimentos utilizan MNIST. PyTorch lo descarga autom\u00e1ticamente en la primera ejecuci\u00f3n. ./data/ # Se crea al correr los scripts por primera vez","title":"Descarga de datasets"},{"location":"installation/#prueba-rapida","text":"python src/app.py Esto ejecuta un pipeline de ejemplo con la arquitectura BONN.","title":"Prueba r\u00e1pida"},{"location":"technical/","text":"Detalles T\u00e9cnicos de BONN Este proyecto implementa modelos inspirados en el sistema olfativo de los insectos, centrado en arquitecturas con: Proyecciones aleatorias parcialmente estructuradas Codificaci\u00f3n dispersa (sparse coding) Especializaci\u00f3n funcional Aprendizaje superficial (shallow learning) Arquitectura BONN Proyecci\u00f3n fija: AL \u2192 KC (capa de expansi\u00f3n) Aprendizaje: capa lineal de salida (MBON) Activaciones: funciones tipo sigmoide y control de escasez por par\u00e1metros s , pc GateBONN (versi\u00f3n bayesiana) Implementado en PyTorch Gating estoc\u00e1stico usando relajaci\u00f3n Gumbel-Sigmoid Regularizaci\u00f3n KL con distribuci\u00f3n Beta Estimaci\u00f3n de informaci\u00f3n mutua entre activaci\u00f3n y etiquetas Ensamble BONN M\u00faltiples modelos entrenados independientemente Predicci\u00f3n promedio de sus salidas (softmax) Evaluaci\u00f3n de precisi\u00f3n seg\u00fan tama\u00f1o del ensamble Experimentos Comparaci\u00f3n con MLP, RFM y ELM Robustez ante pruning sin reentrenamiento Medida de multimodalidad en activaci\u00f3n de KCs Eficiencia en escenarios de pocos datos Entradas y salidas Datos: MNIST Entrada: vectores 784-D normalizados Salida: logits o probabilidades sobre 10 clases C\u00f3digo GPU BONN: usa CuPy para operaciones vectorizadas GateBONN: usa PyTorch con GPU Pruning, an\u00e1lisis y visualizaciones compatibles con NumPy o CuPy Para m\u00e1s detalles conceptuales, consulta el cap\u00edtulo de desarrollo del TFM.","title":"Detalles T\u00e9cnicos"},{"location":"technical/#detalles-tecnicos-de-bonn","text":"Este proyecto implementa modelos inspirados en el sistema olfativo de los insectos, centrado en arquitecturas con: Proyecciones aleatorias parcialmente estructuradas Codificaci\u00f3n dispersa (sparse coding) Especializaci\u00f3n funcional Aprendizaje superficial (shallow learning)","title":"Detalles T\u00e9cnicos de BONN"},{"location":"technical/#arquitectura-bonn","text":"Proyecci\u00f3n fija: AL \u2192 KC (capa de expansi\u00f3n) Aprendizaje: capa lineal de salida (MBON) Activaciones: funciones tipo sigmoide y control de escasez por par\u00e1metros s , pc","title":"Arquitectura BONN"},{"location":"technical/#gatebonn-version-bayesiana","text":"Implementado en PyTorch Gating estoc\u00e1stico usando relajaci\u00f3n Gumbel-Sigmoid Regularizaci\u00f3n KL con distribuci\u00f3n Beta Estimaci\u00f3n de informaci\u00f3n mutua entre activaci\u00f3n y etiquetas","title":"GateBONN (versi\u00f3n bayesiana)"},{"location":"technical/#ensamble-bonn","text":"M\u00faltiples modelos entrenados independientemente Predicci\u00f3n promedio de sus salidas (softmax) Evaluaci\u00f3n de precisi\u00f3n seg\u00fan tama\u00f1o del ensamble","title":"Ensamble BONN"},{"location":"technical/#experimentos","text":"Comparaci\u00f3n con MLP, RFM y ELM Robustez ante pruning sin reentrenamiento Medida de multimodalidad en activaci\u00f3n de KCs Eficiencia en escenarios de pocos datos","title":"Experimentos"},{"location":"technical/#entradas-y-salidas","text":"Datos: MNIST Entrada: vectores 784-D normalizados Salida: logits o probabilidades sobre 10 clases","title":"Entradas y salidas"},{"location":"technical/#codigo-gpu","text":"BONN: usa CuPy para operaciones vectorizadas GateBONN: usa PyTorch con GPU Pruning, an\u00e1lisis y visualizaciones compatibles con NumPy o CuPy Para m\u00e1s detalles conceptuales, consulta el cap\u00edtulo de desarrollo del TFM.","title":"C\u00f3digo GPU"},{"location":"usage/","text":"Uso del proyecto BONN A continuaci\u00f3n se detallan ejemplos de c\u00f3mo ejecutar diferentes experimentos y modelos desde el repositorio. 1. Ejecutar BONN con entrenamiento superficial python src/app.py Este script entrena el modelo BONN con una sola capa entrenable tras proyecciones fijas y mide su precisi\u00f3n. 2. Ejecutar GateBONN (PyTorch) python src/gatebonn/gatebonn_experiment.py Este script entrena GateBONN sobre MNIST para distintos tama\u00f1os de entrenamiento y devuelve un DataFrame con la precisi\u00f3n media y desviaci\u00f3n est\u00e1ndar. 3. Evaluar ensambles BONN from src.ensemble.ensemble_bonn import EnsembleBONN Puedes construir un ensamble de modelos BONN con: ensemble = EnsembleBONN(fit_fn=my_fit_function) accs = ensemble.evaluate_ensemble(X_test, y_test, ensemble_sizes=[1, 2, 5, 10]) 4. An\u00e1lisis de activaci\u00f3n y escasez from src.analysis.multimodality import analyze_kc_digit_multimodality from src.analysis.neuron_ranking import kill_progressive_neurons Estos m\u00f3dulos permiten medir multimodalidad y simular pruning sobre las KCs. 5. Visualizaci\u00f3n de resultados from src.analysis.plot_utils import plot_surfaces_adjusted from src.analysis.pruning_analysis import plot_pruning_progress_stylized Las funciones de visualizaci\u00f3n permiten comparar arquitecturas y evaluar degradaci\u00f3n de precisi\u00f3n ante eliminaci\u00f3n de neuronas.","title":"Uso"},{"location":"usage/#uso-del-proyecto-bonn","text":"A continuaci\u00f3n se detallan ejemplos de c\u00f3mo ejecutar diferentes experimentos y modelos desde el repositorio.","title":"Uso del proyecto BONN"},{"location":"usage/#1-ejecutar-bonn-con-entrenamiento-superficial","text":"python src/app.py Este script entrena el modelo BONN con una sola capa entrenable tras proyecciones fijas y mide su precisi\u00f3n.","title":"1. Ejecutar BONN con entrenamiento superficial"},{"location":"usage/#2-ejecutar-gatebonn-pytorch","text":"python src/gatebonn/gatebonn_experiment.py Este script entrena GateBONN sobre MNIST para distintos tama\u00f1os de entrenamiento y devuelve un DataFrame con la precisi\u00f3n media y desviaci\u00f3n est\u00e1ndar.","title":"2. Ejecutar GateBONN (PyTorch)"},{"location":"usage/#3-evaluar-ensambles-bonn","text":"from src.ensemble.ensemble_bonn import EnsembleBONN Puedes construir un ensamble de modelos BONN con: ensemble = EnsembleBONN(fit_fn=my_fit_function) accs = ensemble.evaluate_ensemble(X_test, y_test, ensemble_sizes=[1, 2, 5, 10])","title":"3. Evaluar ensambles BONN"},{"location":"usage/#4-analisis-de-activacion-y-escasez","text":"from src.analysis.multimodality import analyze_kc_digit_multimodality from src.analysis.neuron_ranking import kill_progressive_neurons Estos m\u00f3dulos permiten medir multimodalidad y simular pruning sobre las KCs.","title":"4. An\u00e1lisis de activaci\u00f3n y escasez"},{"location":"usage/#5-visualizacion-de-resultados","text":"from src.analysis.plot_utils import plot_surfaces_adjusted from src.analysis.pruning_analysis import plot_pruning_progress_stylized Las funciones de visualizaci\u00f3n permiten comparar arquitecturas y evaluar degradaci\u00f3n de precisi\u00f3n ante eliminaci\u00f3n de neuronas.","title":"5. Visualizaci\u00f3n de resultados"}]}